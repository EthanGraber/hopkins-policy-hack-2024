{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from dailyActivity_merged.csv:\n",
      "           Id ActivityDate  TotalSteps  TotalDistance  TrackerDistance  \\\n",
      "0  1503960366    3/25/2016       11004           7.11             7.11   \n",
      "1  1503960366    3/26/2016       17609          11.55            11.55   \n",
      "2  1503960366    3/27/2016       12736           8.53             8.53   \n",
      "3  1503960366    3/28/2016       13231           8.93             8.93   \n",
      "4  1503960366    3/29/2016       12041           7.85             7.85   \n",
      "\n",
      "   LoggedActivitiesDistance  VeryActiveDistance  ModeratelyActiveDistance  \\\n",
      "0                       0.0                2.57                      0.46   \n",
      "1                       0.0                6.92                      0.73   \n",
      "2                       0.0                4.66                      0.16   \n",
      "3                       0.0                3.19                      0.79   \n",
      "4                       0.0                2.16                      1.09   \n",
      "\n",
      "   LightActiveDistance  SedentaryActiveDistance  VeryActiveMinutes  \\\n",
      "0                 4.07                      0.0                 33   \n",
      "1                 3.91                      0.0                 89   \n",
      "2                 3.71                      0.0                 56   \n",
      "3                 4.95                      0.0                 39   \n",
      "4                 4.61                      0.0                 28   \n",
      "\n",
      "   FairlyActiveMinutes  LightlyActiveMinutes  SedentaryMinutes  Calories  \n",
      "0                   12                   205               804      1819  \n",
      "1                   17                   274               588      2154  \n",
      "2                    5                   268               605      1944  \n",
      "3                   20                   224              1080      1932  \n",
      "4                   28                   243               763      1886  \n",
      "Data from heartrate_seconds_merged.csv:\n",
      "           Id                 Time  Value\n",
      "0  2022484408  4/1/2016 7:54:00 AM     93\n",
      "1  2022484408  4/1/2016 7:54:05 AM     91\n",
      "2  2022484408  4/1/2016 7:54:10 AM     96\n",
      "3  2022484408  4/1/2016 7:54:15 AM     98\n",
      "4  2022484408  4/1/2016 7:54:20 AM    100\n",
      "Data from minuteIntensitiesNarrow_merged.csv:\n",
      "           Id         ActivityMinute  Intensity\n",
      "0  1503960366  3/12/2016 12:00:00 AM          0\n",
      "1  1503960366  3/12/2016 12:01:00 AM          0\n",
      "2  1503960366  3/12/2016 12:02:00 AM          0\n",
      "3  1503960366  3/12/2016 12:03:00 AM          0\n",
      "4  1503960366  3/12/2016 12:04:00 AM          0\n",
      "Data from minuteMETsNarrow_merged.csv:\n",
      "           Id         ActivityMinute  METs\n",
      "0  1503960366  3/12/2016 12:00:00 AM    10\n",
      "1  1503960366  3/12/2016 12:01:00 AM    10\n",
      "2  1503960366  3/12/2016 12:02:00 AM    10\n",
      "3  1503960366  3/12/2016 12:03:00 AM    10\n",
      "4  1503960366  3/12/2016 12:04:00 AM    10\n",
      "Data from hourlySteps_merged.csv:\n",
      "           Id           ActivityHour  StepTotal\n",
      "0  1503960366  3/12/2016 12:00:00 AM          0\n",
      "1  1503960366   3/12/2016 1:00:00 AM          0\n",
      "2  1503960366   3/12/2016 2:00:00 AM          0\n",
      "3  1503960366   3/12/2016 3:00:00 AM          0\n",
      "4  1503960366   3/12/2016 4:00:00 AM          0\n",
      "Data from hourlyIntensities_merged.csv:\n",
      "           Id           ActivityHour  TotalIntensity  AverageIntensity\n",
      "0  1503960366  3/12/2016 12:00:00 AM               0               0.0\n",
      "1  1503960366   3/12/2016 1:00:00 AM               0               0.0\n",
      "2  1503960366   3/12/2016 2:00:00 AM               0               0.0\n",
      "3  1503960366   3/12/2016 3:00:00 AM               0               0.0\n",
      "4  1503960366   3/12/2016 4:00:00 AM               0               0.0\n",
      "Data from hourlyCalories_merged.csv:\n",
      "           Id           ActivityHour  Calories\n",
      "0  1503960366  3/12/2016 12:00:00 AM        48\n",
      "1  1503960366   3/12/2016 1:00:00 AM        48\n",
      "2  1503960366   3/12/2016 2:00:00 AM        48\n",
      "3  1503960366   3/12/2016 3:00:00 AM        48\n",
      "4  1503960366   3/12/2016 4:00:00 AM        48\n",
      "Data from minuteSleep_merged.csv:\n",
      "           Id                  date  value        logId\n",
      "0  1503960366  3/13/2016 2:39:30 AM      1  11114919637\n",
      "1  1503960366  3/13/2016 2:40:30 AM      1  11114919637\n",
      "2  1503960366  3/13/2016 2:41:30 AM      1  11114919637\n",
      "3  1503960366  3/13/2016 2:42:30 AM      1  11114919637\n",
      "4  1503960366  3/13/2016 2:43:30 AM      1  11114919637\n",
      "Data from minuteCaloriesNarrow_merged.csv:\n",
      "           Id         ActivityMinute  Calories\n",
      "0  1503960366  3/12/2016 12:00:00 AM    0.7973\n",
      "1  1503960366  3/12/2016 12:01:00 AM    0.7973\n",
      "2  1503960366  3/12/2016 12:02:00 AM    0.7973\n",
      "3  1503960366  3/12/2016 12:03:00 AM    0.7973\n",
      "4  1503960366  3/12/2016 12:04:00 AM    0.7973\n",
      "Data from minuteStepsNarrow_merged.csv:\n",
      "           Id         ActivityMinute  Steps\n",
      "0  1503960366  3/12/2016 12:00:00 AM      0\n",
      "1  1503960366  3/12/2016 12:01:00 AM      0\n",
      "2  1503960366  3/12/2016 12:02:00 AM      0\n",
      "3  1503960366  3/12/2016 12:03:00 AM      0\n",
      "4  1503960366  3/12/2016 12:04:00 AM      0\n",
      "Data from weightLogInfo_merged.csv:\n",
      "           Id                  Date    WeightKg  WeightPounds   Fat  \\\n",
      "0  1503960366  4/5/2016 11:59:59 PM   53.299999    117.506384  22.0   \n",
      "1  1927972279  4/10/2016 6:33:26 PM  129.600006    285.719105   NaN   \n",
      "2  2347167796  4/3/2016 11:59:59 PM   63.400002    139.773078  10.0   \n",
      "3  2873212765  4/6/2016 11:59:59 PM   56.700001    125.002104   NaN   \n",
      "4  2873212765  4/7/2016 11:59:59 PM   57.200001    126.104416   NaN   \n",
      "\n",
      "         BMI  IsManualReport          LogId  \n",
      "0  22.969999            True  1459900799000  \n",
      "1  46.169998           False  1460313206000  \n",
      "2  24.770000            True  1459727999000  \n",
      "3  21.450001            True  1459987199000  \n",
      "4  21.650000            True  1460073599000  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# df = pd.read_csv('')\n",
    "# Loop through all CSV files in the current directory\n",
    "data_dict = {}\n",
    "\n",
    "for filename in os.listdir('.'):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "        data_dict[filename] = df\n",
    "        print(f\"Data from {filename}:\")\n",
    "        print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1503960366/1503960366_dailyActivity_merged.csv\n",
      "Saved 1624580081/1624580081_dailyActivity_merged.csv\n",
      "Saved 1644430081/1644430081_dailyActivity_merged.csv\n",
      "Saved 1844505072/1844505072_dailyActivity_merged.csv\n",
      "Saved 1927972279/1927972279_dailyActivity_merged.csv\n",
      "Saved 2022484408/2022484408_dailyActivity_merged.csv\n",
      "Saved 2026352035/2026352035_dailyActivity_merged.csv\n",
      "Saved 2320127002/2320127002_dailyActivity_merged.csv\n",
      "Saved 2347167796/2347167796_dailyActivity_merged.csv\n",
      "Saved 2873212765/2873212765_dailyActivity_merged.csv\n",
      "Saved 2891001357/2891001357_dailyActivity_merged.csv\n",
      "Saved 3372868164/3372868164_dailyActivity_merged.csv\n",
      "Saved 3977333714/3977333714_dailyActivity_merged.csv\n",
      "Saved 4020332650/4020332650_dailyActivity_merged.csv\n",
      "Saved 4057192912/4057192912_dailyActivity_merged.csv\n",
      "Saved 4319703577/4319703577_dailyActivity_merged.csv\n",
      "Saved 4388161847/4388161847_dailyActivity_merged.csv\n",
      "Saved 4445114986/4445114986_dailyActivity_merged.csv\n",
      "Saved 4558609924/4558609924_dailyActivity_merged.csv\n",
      "Saved 4702921684/4702921684_dailyActivity_merged.csv\n",
      "Saved 5553957443/5553957443_dailyActivity_merged.csv\n",
      "Saved 5577150313/5577150313_dailyActivity_merged.csv\n",
      "Saved 6117666160/6117666160_dailyActivity_merged.csv\n",
      "Saved 6290855005/6290855005_dailyActivity_merged.csv\n",
      "Saved 6391747486/6391747486_dailyActivity_merged.csv\n",
      "Saved 6775888955/6775888955_dailyActivity_merged.csv\n",
      "Saved 6962181067/6962181067_dailyActivity_merged.csv\n",
      "Saved 7007744171/7007744171_dailyActivity_merged.csv\n",
      "Saved 7086361926/7086361926_dailyActivity_merged.csv\n",
      "Saved 8053475328/8053475328_dailyActivity_merged.csv\n",
      "Saved 8253242879/8253242879_dailyActivity_merged.csv\n",
      "Saved 8378563200/8378563200_dailyActivity_merged.csv\n",
      "Saved 8583815059/8583815059_dailyActivity_merged.csv\n",
      "Saved 8792009665/8792009665_dailyActivity_merged.csv\n",
      "Saved 8877689391/8877689391_dailyActivity_merged.csv\n",
      "Saved 2022484408/2022484408_heartrate_seconds_merged.csv\n",
      "Saved 2026352035/2026352035_heartrate_seconds_merged.csv\n",
      "Saved 2347167796/2347167796_heartrate_seconds_merged.csv\n",
      "Saved 4020332650/4020332650_heartrate_seconds_merged.csv\n",
      "Saved 4558609924/4558609924_heartrate_seconds_merged.csv\n",
      "Saved 5553957443/5553957443_heartrate_seconds_merged.csv\n",
      "Saved 5577150313/5577150313_heartrate_seconds_merged.csv\n",
      "Saved 6117666160/6117666160_heartrate_seconds_merged.csv\n",
      "Saved 6391747486/6391747486_heartrate_seconds_merged.csv\n",
      "Saved 6775888955/6775888955_heartrate_seconds_merged.csv\n",
      "Saved 6962181067/6962181067_heartrate_seconds_merged.csv\n",
      "Saved 7007744171/7007744171_heartrate_seconds_merged.csv\n",
      "Saved 8792009665/8792009665_heartrate_seconds_merged.csv\n",
      "Saved 8877689391/8877689391_heartrate_seconds_merged.csv\n",
      "Saved 1503960366/1503960366_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 1624580081/1624580081_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 1644430081/1644430081_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 1844505072/1844505072_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 1927972279/1927972279_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 2022484408/2022484408_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 2026352035/2026352035_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 2320127002/2320127002_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 2347167796/2347167796_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 2873212765/2873212765_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 2891001357/2891001357_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 3372868164/3372868164_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 3977333714/3977333714_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 4020332650/4020332650_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 4057192912/4057192912_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 4319703577/4319703577_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 4445114986/4445114986_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 4558609924/4558609924_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 4702921684/4702921684_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 5553957443/5553957443_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 5577150313/5577150313_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 6117666160/6117666160_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 6290855005/6290855005_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 6391747486/6391747486_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 6775888955/6775888955_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 6962181067/6962181067_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 7007744171/7007744171_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 7086361926/7086361926_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 8053475328/8053475328_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 8253242879/8253242879_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 8378563200/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 8583815059/8583815059_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 8792009665/8792009665_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 8877689391/8877689391_minuteIntensitiesNarrow_merged.csv\n",
      "Saved 1503960366/1503960366_minuteMETsNarrow_merged.csv\n",
      "Saved 1624580081/1624580081_minuteMETsNarrow_merged.csv\n",
      "Saved 1644430081/1644430081_minuteMETsNarrow_merged.csv\n",
      "Saved 1844505072/1844505072_minuteMETsNarrow_merged.csv\n",
      "Saved 1927972279/1927972279_minuteMETsNarrow_merged.csv\n",
      "Saved 2022484408/2022484408_minuteMETsNarrow_merged.csv\n",
      "Saved 2026352035/2026352035_minuteMETsNarrow_merged.csv\n",
      "Saved 2320127002/2320127002_minuteMETsNarrow_merged.csv\n",
      "Saved 2347167796/2347167796_minuteMETsNarrow_merged.csv\n",
      "Saved 2873212765/2873212765_minuteMETsNarrow_merged.csv\n",
      "Saved 2891001357/2891001357_minuteMETsNarrow_merged.csv\n",
      "Saved 3372868164/3372868164_minuteMETsNarrow_merged.csv\n",
      "Saved 3977333714/3977333714_minuteMETsNarrow_merged.csv\n",
      "Saved 4020332650/4020332650_minuteMETsNarrow_merged.csv\n",
      "Saved 4057192912/4057192912_minuteMETsNarrow_merged.csv\n",
      "Saved 4319703577/4319703577_minuteMETsNarrow_merged.csv\n",
      "Saved 4445114986/4445114986_minuteMETsNarrow_merged.csv\n",
      "Saved 4558609924/4558609924_minuteMETsNarrow_merged.csv\n",
      "Saved 4702921684/4702921684_minuteMETsNarrow_merged.csv\n",
      "Saved 5553957443/5553957443_minuteMETsNarrow_merged.csv\n",
      "Saved 5577150313/5577150313_minuteMETsNarrow_merged.csv\n",
      "Saved 6117666160/6117666160_minuteMETsNarrow_merged.csv\n",
      "Saved 6290855005/6290855005_minuteMETsNarrow_merged.csv\n",
      "Saved 6391747486/6391747486_minuteMETsNarrow_merged.csv\n",
      "Saved 6775888955/6775888955_minuteMETsNarrow_merged.csv\n",
      "Saved 6962181067/6962181067_minuteMETsNarrow_merged.csv\n",
      "Saved 7007744171/7007744171_minuteMETsNarrow_merged.csv\n",
      "Saved 7086361926/7086361926_minuteMETsNarrow_merged.csv\n",
      "Saved 8053475328/8053475328_minuteMETsNarrow_merged.csv\n",
      "Saved 8253242879/8253242879_minuteMETsNarrow_merged.csv\n",
      "Saved 8378563200/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved 8583815059/8583815059_minuteMETsNarrow_merged.csv\n",
      "Saved 8792009665/8792009665_minuteMETsNarrow_merged.csv\n",
      "Saved 8877689391/8877689391_minuteMETsNarrow_merged.csv\n",
      "Saved 1503960366/1503960366_hourlySteps_merged.csv\n",
      "Saved 1624580081/1624580081_hourlySteps_merged.csv\n",
      "Saved 1644430081/1644430081_hourlySteps_merged.csv\n",
      "Saved 1844505072/1844505072_hourlySteps_merged.csv\n",
      "Saved 1927972279/1927972279_hourlySteps_merged.csv\n",
      "Saved 2022484408/2022484408_hourlySteps_merged.csv\n",
      "Saved 2026352035/2026352035_hourlySteps_merged.csv\n",
      "Saved 2320127002/2320127002_hourlySteps_merged.csv\n",
      "Saved 2347167796/2347167796_hourlySteps_merged.csv\n",
      "Saved 2873212765/2873212765_hourlySteps_merged.csv\n",
      "Saved 2891001357/2891001357_hourlySteps_merged.csv\n",
      "Saved 3372868164/3372868164_hourlySteps_merged.csv\n",
      "Saved 3977333714/3977333714_hourlySteps_merged.csv\n",
      "Saved 4020332650/4020332650_hourlySteps_merged.csv\n",
      "Saved 4057192912/4057192912_hourlySteps_merged.csv\n",
      "Saved 4319703577/4319703577_hourlySteps_merged.csv\n",
      "Saved 4445114986/4445114986_hourlySteps_merged.csv\n",
      "Saved 4558609924/4558609924_hourlySteps_merged.csv\n",
      "Saved 4702921684/4702921684_hourlySteps_merged.csv\n",
      "Saved 5553957443/5553957443_hourlySteps_merged.csv\n",
      "Saved 5577150313/5577150313_hourlySteps_merged.csv\n",
      "Saved 6117666160/6117666160_hourlySteps_merged.csv\n",
      "Saved 6290855005/6290855005_hourlySteps_merged.csv\n",
      "Saved 6391747486/6391747486_hourlySteps_merged.csv\n",
      "Saved 6775888955/6775888955_hourlySteps_merged.csv\n",
      "Saved 6962181067/6962181067_hourlySteps_merged.csv\n",
      "Saved 7007744171/7007744171_hourlySteps_merged.csv\n",
      "Saved 7086361926/7086361926_hourlySteps_merged.csv\n",
      "Saved 8053475328/8053475328_hourlySteps_merged.csv\n",
      "Saved 8253242879/8253242879_hourlySteps_merged.csv\n",
      "Saved 8378563200/8378563200_hourlySteps_merged.csv\n",
      "Saved 8583815059/8583815059_hourlySteps_merged.csv\n",
      "Saved 8792009665/8792009665_hourlySteps_merged.csv\n",
      "Saved 8877689391/8877689391_hourlySteps_merged.csv\n",
      "Saved 1503960366/1503960366_hourlyIntensities_merged.csv\n",
      "Saved 1624580081/1624580081_hourlyIntensities_merged.csv\n",
      "Saved 1644430081/1644430081_hourlyIntensities_merged.csv\n",
      "Saved 1844505072/1844505072_hourlyIntensities_merged.csv\n",
      "Saved 1927972279/1927972279_hourlyIntensities_merged.csv\n",
      "Saved 2022484408/2022484408_hourlyIntensities_merged.csv\n",
      "Saved 2026352035/2026352035_hourlyIntensities_merged.csv\n",
      "Saved 2320127002/2320127002_hourlyIntensities_merged.csv\n",
      "Saved 2347167796/2347167796_hourlyIntensities_merged.csv\n",
      "Saved 2873212765/2873212765_hourlyIntensities_merged.csv\n",
      "Saved 2891001357/2891001357_hourlyIntensities_merged.csv\n",
      "Saved 3372868164/3372868164_hourlyIntensities_merged.csv\n",
      "Saved 3977333714/3977333714_hourlyIntensities_merged.csv\n",
      "Saved 4020332650/4020332650_hourlyIntensities_merged.csv\n",
      "Saved 4057192912/4057192912_hourlyIntensities_merged.csv\n",
      "Saved 4319703577/4319703577_hourlyIntensities_merged.csv\n",
      "Saved 4445114986/4445114986_hourlyIntensities_merged.csv\n",
      "Saved 4558609924/4558609924_hourlyIntensities_merged.csv\n",
      "Saved 4702921684/4702921684_hourlyIntensities_merged.csv\n",
      "Saved 5553957443/5553957443_hourlyIntensities_merged.csv\n",
      "Saved 5577150313/5577150313_hourlyIntensities_merged.csv\n",
      "Saved 6117666160/6117666160_hourlyIntensities_merged.csv\n",
      "Saved 6290855005/6290855005_hourlyIntensities_merged.csv\n",
      "Saved 6391747486/6391747486_hourlyIntensities_merged.csv\n",
      "Saved 6775888955/6775888955_hourlyIntensities_merged.csv\n",
      "Saved 6962181067/6962181067_hourlyIntensities_merged.csv\n",
      "Saved 7007744171/7007744171_hourlyIntensities_merged.csv\n",
      "Saved 7086361926/7086361926_hourlyIntensities_merged.csv\n",
      "Saved 8053475328/8053475328_hourlyIntensities_merged.csv\n",
      "Saved 8253242879/8253242879_hourlyIntensities_merged.csv\n",
      "Saved 8378563200/8378563200_hourlyIntensities_merged.csv\n",
      "Saved 8583815059/8583815059_hourlyIntensities_merged.csv\n",
      "Saved 8792009665/8792009665_hourlyIntensities_merged.csv\n",
      "Saved 8877689391/8877689391_hourlyIntensities_merged.csv\n",
      "Saved 1503960366/1503960366_hourlyCalories_merged.csv\n",
      "Saved 1624580081/1624580081_hourlyCalories_merged.csv\n",
      "Saved 1644430081/1644430081_hourlyCalories_merged.csv\n",
      "Saved 1844505072/1844505072_hourlyCalories_merged.csv\n",
      "Saved 1927972279/1927972279_hourlyCalories_merged.csv\n",
      "Saved 2022484408/2022484408_hourlyCalories_merged.csv\n",
      "Saved 2026352035/2026352035_hourlyCalories_merged.csv\n",
      "Saved 2320127002/2320127002_hourlyCalories_merged.csv\n",
      "Saved 2347167796/2347167796_hourlyCalories_merged.csv\n",
      "Saved 2873212765/2873212765_hourlyCalories_merged.csv\n",
      "Saved 2891001357/2891001357_hourlyCalories_merged.csv\n",
      "Saved 3372868164/3372868164_hourlyCalories_merged.csv\n",
      "Saved 3977333714/3977333714_hourlyCalories_merged.csv\n",
      "Saved 4020332650/4020332650_hourlyCalories_merged.csv\n",
      "Saved 4057192912/4057192912_hourlyCalories_merged.csv\n",
      "Saved 4319703577/4319703577_hourlyCalories_merged.csv\n",
      "Saved 4445114986/4445114986_hourlyCalories_merged.csv\n",
      "Saved 4558609924/4558609924_hourlyCalories_merged.csv\n",
      "Saved 4702921684/4702921684_hourlyCalories_merged.csv\n",
      "Saved 5553957443/5553957443_hourlyCalories_merged.csv\n",
      "Saved 5577150313/5577150313_hourlyCalories_merged.csv\n",
      "Saved 6117666160/6117666160_hourlyCalories_merged.csv\n",
      "Saved 6290855005/6290855005_hourlyCalories_merged.csv\n",
      "Saved 6391747486/6391747486_hourlyCalories_merged.csv\n",
      "Saved 6775888955/6775888955_hourlyCalories_merged.csv\n",
      "Saved 6962181067/6962181067_hourlyCalories_merged.csv\n",
      "Saved 7007744171/7007744171_hourlyCalories_merged.csv\n",
      "Saved 7086361926/7086361926_hourlyCalories_merged.csv\n",
      "Saved 8053475328/8053475328_hourlyCalories_merged.csv\n",
      "Saved 8253242879/8253242879_hourlyCalories_merged.csv\n",
      "Saved 8378563200/8378563200_hourlyCalories_merged.csv\n",
      "Saved 8583815059/8583815059_hourlyCalories_merged.csv\n",
      "Saved 8792009665/8792009665_hourlyCalories_merged.csv\n",
      "Saved 8877689391/8877689391_hourlyCalories_merged.csv\n",
      "Saved 1503960366/1503960366_minuteSleep_merged.csv\n",
      "Saved 1644430081/1644430081_minuteSleep_merged.csv\n",
      "Saved 1844505072/1844505072_minuteSleep_merged.csv\n",
      "Saved 1927972279/1927972279_minuteSleep_merged.csv\n",
      "Saved 2022484408/2022484408_minuteSleep_merged.csv\n",
      "Saved 2026352035/2026352035_minuteSleep_merged.csv\n",
      "Saved 2347167796/2347167796_minuteSleep_merged.csv\n",
      "Saved 3977333714/3977333714_minuteSleep_merged.csv\n",
      "Saved 4020332650/4020332650_minuteSleep_merged.csv\n",
      "Saved 4319703577/4319703577_minuteSleep_merged.csv\n",
      "Saved 4445114986/4445114986_minuteSleep_merged.csv\n",
      "Saved 4558609924/4558609924_minuteSleep_merged.csv\n",
      "Saved 4702921684/4702921684_minuteSleep_merged.csv\n",
      "Saved 5553957443/5553957443_minuteSleep_merged.csv\n",
      "Saved 5577150313/5577150313_minuteSleep_merged.csv\n",
      "Saved 6117666160/6117666160_minuteSleep_merged.csv\n",
      "Saved 6775888955/6775888955_minuteSleep_merged.csv\n",
      "Saved 6962181067/6962181067_minuteSleep_merged.csv\n",
      "Saved 7007744171/7007744171_minuteSleep_merged.csv\n",
      "Saved 7086361926/7086361926_minuteSleep_merged.csv\n",
      "Saved 8053475328/8053475328_minuteSleep_merged.csv\n",
      "Saved 8378563200/8378563200_minuteSleep_merged.csv\n",
      "Saved 8792009665/8792009665_minuteSleep_merged.csv\n",
      "Saved 1503960366/1503960366_minuteCaloriesNarrow_merged.csv\n",
      "Saved 1624580081/1624580081_minuteCaloriesNarrow_merged.csv\n",
      "Saved 1644430081/1644430081_minuteCaloriesNarrow_merged.csv\n",
      "Saved 1844505072/1844505072_minuteCaloriesNarrow_merged.csv\n",
      "Saved 1927972279/1927972279_minuteCaloriesNarrow_merged.csv\n",
      "Saved 2022484408/2022484408_minuteCaloriesNarrow_merged.csv\n",
      "Saved 2026352035/2026352035_minuteCaloriesNarrow_merged.csv\n",
      "Saved 2320127002/2320127002_minuteCaloriesNarrow_merged.csv\n",
      "Saved 2347167796/2347167796_minuteCaloriesNarrow_merged.csv\n",
      "Saved 2873212765/2873212765_minuteCaloriesNarrow_merged.csv\n",
      "Saved 2891001357/2891001357_minuteCaloriesNarrow_merged.csv\n",
      "Saved 3372868164/3372868164_minuteCaloriesNarrow_merged.csv\n",
      "Saved 3977333714/3977333714_minuteCaloriesNarrow_merged.csv\n",
      "Saved 4020332650/4020332650_minuteCaloriesNarrow_merged.csv\n",
      "Saved 4057192912/4057192912_minuteCaloriesNarrow_merged.csv\n",
      "Saved 4319703577/4319703577_minuteCaloriesNarrow_merged.csv\n",
      "Saved 4445114986/4445114986_minuteCaloriesNarrow_merged.csv\n",
      "Saved 4558609924/4558609924_minuteCaloriesNarrow_merged.csv\n",
      "Saved 4702921684/4702921684_minuteCaloriesNarrow_merged.csv\n",
      "Saved 5553957443/5553957443_minuteCaloriesNarrow_merged.csv\n",
      "Saved 5577150313/5577150313_minuteCaloriesNarrow_merged.csv\n",
      "Saved 6117666160/6117666160_minuteCaloriesNarrow_merged.csv\n",
      "Saved 6290855005/6290855005_minuteCaloriesNarrow_merged.csv\n",
      "Saved 6391747486/6391747486_minuteCaloriesNarrow_merged.csv\n",
      "Saved 6775888955/6775888955_minuteCaloriesNarrow_merged.csv\n",
      "Saved 6962181067/6962181067_minuteCaloriesNarrow_merged.csv\n",
      "Saved 7007744171/7007744171_minuteCaloriesNarrow_merged.csv\n",
      "Saved 7086361926/7086361926_minuteCaloriesNarrow_merged.csv\n",
      "Saved 8053475328/8053475328_minuteCaloriesNarrow_merged.csv\n",
      "Saved 8253242879/8253242879_minuteCaloriesNarrow_merged.csv\n",
      "Saved 8378563200/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved 8583815059/8583815059_minuteCaloriesNarrow_merged.csv\n",
      "Saved 8792009665/8792009665_minuteCaloriesNarrow_merged.csv\n",
      "Saved 8877689391/8877689391_minuteCaloriesNarrow_merged.csv\n",
      "Saved 1503960366/1503960366_minuteStepsNarrow_merged.csv\n",
      "Saved 1624580081/1624580081_minuteStepsNarrow_merged.csv\n",
      "Saved 1644430081/1644430081_minuteStepsNarrow_merged.csv\n",
      "Saved 1844505072/1844505072_minuteStepsNarrow_merged.csv\n",
      "Saved 1927972279/1927972279_minuteStepsNarrow_merged.csv\n",
      "Saved 2022484408/2022484408_minuteStepsNarrow_merged.csv\n",
      "Saved 2026352035/2026352035_minuteStepsNarrow_merged.csv\n",
      "Saved 2320127002/2320127002_minuteStepsNarrow_merged.csv\n",
      "Saved 2347167796/2347167796_minuteStepsNarrow_merged.csv\n",
      "Saved 2873212765/2873212765_minuteStepsNarrow_merged.csv\n",
      "Saved 2891001357/2891001357_minuteStepsNarrow_merged.csv\n",
      "Saved 3372868164/3372868164_minuteStepsNarrow_merged.csv\n",
      "Saved 3977333714/3977333714_minuteStepsNarrow_merged.csv\n",
      "Saved 4020332650/4020332650_minuteStepsNarrow_merged.csv\n",
      "Saved 4057192912/4057192912_minuteStepsNarrow_merged.csv\n",
      "Saved 4319703577/4319703577_minuteStepsNarrow_merged.csv\n",
      "Saved 4445114986/4445114986_minuteStepsNarrow_merged.csv\n",
      "Saved 4558609924/4558609924_minuteStepsNarrow_merged.csv\n",
      "Saved 4702921684/4702921684_minuteStepsNarrow_merged.csv\n",
      "Saved 5553957443/5553957443_minuteStepsNarrow_merged.csv\n",
      "Saved 5577150313/5577150313_minuteStepsNarrow_merged.csv\n",
      "Saved 6117666160/6117666160_minuteStepsNarrow_merged.csv\n",
      "Saved 6290855005/6290855005_minuteStepsNarrow_merged.csv\n",
      "Saved 6391747486/6391747486_minuteStepsNarrow_merged.csv\n",
      "Saved 6775888955/6775888955_minuteStepsNarrow_merged.csv\n",
      "Saved 6962181067/6962181067_minuteStepsNarrow_merged.csv\n",
      "Saved 7007744171/7007744171_minuteStepsNarrow_merged.csv\n",
      "Saved 7086361926/7086361926_minuteStepsNarrow_merged.csv\n",
      "Saved 8053475328/8053475328_minuteStepsNarrow_merged.csv\n",
      "Saved 8253242879/8253242879_minuteStepsNarrow_merged.csv\n",
      "Saved 8378563200/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved 8583815059/8583815059_minuteStepsNarrow_merged.csv\n",
      "Saved 8792009665/8792009665_minuteStepsNarrow_merged.csv\n",
      "Saved 8877689391/8877689391_minuteStepsNarrow_merged.csv\n",
      "Saved 1503960366/1503960366_weightLogInfo_merged.csv\n",
      "Saved 1927972279/1927972279_weightLogInfo_merged.csv\n",
      "Saved 2347167796/2347167796_weightLogInfo_merged.csv\n",
      "Saved 2873212765/2873212765_weightLogInfo_merged.csv\n",
      "Saved 2891001357/2891001357_weightLogInfo_merged.csv\n",
      "Saved 4445114986/4445114986_weightLogInfo_merged.csv\n",
      "Saved 4558609924/4558609924_weightLogInfo_merged.csv\n",
      "Saved 4702921684/4702921684_weightLogInfo_merged.csv\n",
      "Saved 6962181067/6962181067_weightLogInfo_merged.csv\n",
      "Saved 8253242879/8253242879_weightLogInfo_merged.csv\n",
      "Saved 8877689391/8877689391_weightLogInfo_merged.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def split_and_save_by_id(data_dict):\n",
    "    for filename, df in data_dict.items():\n",
    "        if 'Id' in df.columns:\n",
    "            grouped = df.groupby('Id')\n",
    "            for user_id, group in grouped:\n",
    "                # Create a directory for the user ID if it doesn't exist\n",
    "                user_dir = str(user_id)\n",
    "                os.makedirs(user_dir, exist_ok=True)\n",
    "                \n",
    "                # Save the CSV file in the user's directory\n",
    "                output_filename = os.path.join(user_dir, f\"{user_id}_{filename}\")\n",
    "                group.to_csv(output_filename, index=False)\n",
    "                print(f\"Saved {output_filename}\")\n",
    "\n",
    "# Call the function\n",
    "split_and_save_by_id(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ./8378563200/2016-04-01/8378563200_dailyActivity_merged.csv\n",
      "Saved ./8378563200/2016-04-02/8378563200_dailyActivity_merged.csv\n",
      "Saved ./8378563200/2016-04-03/8378563200_dailyActivity_merged.csv\n",
      "Saved ./8378563200/2016-04-04/8378563200_dailyActivity_merged.csv\n",
      "Saved ./8378563200/2016-04-05/8378563200_dailyActivity_merged.csv\n",
      "Saved ./8378563200/2016-04-06/8378563200_dailyActivity_merged.csv\n",
      "Saved ./8378563200/2016-04-07/8378563200_dailyActivity_merged.csv\n",
      "Saved ./8378563200/2016-04-08/8378563200_dailyActivity_merged.csv\n",
      "Saved ./8378563200/2016-04-09/8378563200_dailyActivity_merged.csv\n",
      "Saved ./8378563200/2016-04-10/8378563200_dailyActivity_merged.csv\n",
      "Saved ./8378563200/2016-04-11/8378563200_dailyActivity_merged.csv\n",
      "Saved ./8378563200/2016-04-12/8378563200_dailyActivity_merged.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4q/_mr1kbyx3hj3j1xbqv071trh0000gn/T/ipykernel_39419/3039414713.py:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['ActivityMinute'] = pd.to_datetime(df['ActivityMinute'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ./8378563200/2016-03-12/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-13/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-14/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-15/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-16/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-17/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-18/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-19/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-20/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-21/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-22/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-23/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-24/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-25/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-26/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-27/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-28/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-29/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-30/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-31/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-01/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-02/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-03/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-04/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-05/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-06/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-07/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-08/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-09/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-10/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-11/8378563200_minuteStepsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-12/8378563200_minuteStepsNarrow_merged.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4q/_mr1kbyx3hj3j1xbqv071trh0000gn/T/ipykernel_39419/3039414713.py:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['ActivityMinute'] = pd.to_datetime(df['ActivityMinute'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ./8378563200/2016-03-12/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-13/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-14/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-15/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-16/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-17/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-18/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-19/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-20/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-21/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-22/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-23/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-24/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-25/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-26/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-27/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-28/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-29/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-30/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-31/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-01/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-02/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-03/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-04/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-05/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-06/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-07/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-08/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-09/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-10/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-11/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-12/8378563200_minuteMETsNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-12/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-13/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-14/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-15/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-16/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-17/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-18/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-19/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-20/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-21/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-22/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-23/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-24/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-25/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-26/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-27/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-28/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-29/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-30/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-31/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-04-01/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-04-02/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-04-03/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-04-04/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-04-05/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-04-06/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-04-07/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-04-08/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-04-09/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-04-10/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-04-11/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-04-12/8378563200_hourlySteps_merged.csv\n",
      "Saved ./8378563200/2016-03-12/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-13/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-14/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-15/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-16/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-17/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-18/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-19/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-20/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-21/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-22/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-23/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-24/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-25/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-26/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-27/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-28/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-29/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-30/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-31/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-04-01/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-04-02/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-04-03/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-04-04/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-04-05/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-04-06/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-04-07/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-04-08/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-04-09/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-04-10/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-04-11/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-04-12/8378563200_hourlyIntensities_merged.csv\n",
      "Saved ./8378563200/2016-03-12/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-13/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-14/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-15/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-16/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-17/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-18/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-19/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-20/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-21/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-22/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-23/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-24/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-25/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-26/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-27/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-28/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-29/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-30/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-03-31/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-04-01/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-04-02/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-04-03/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-04-04/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-04-05/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-04-06/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-04-07/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-04-08/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-04-09/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-04-10/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-04-11/8378563200_hourlyCalories_merged.csv\n",
      "Saved ./8378563200/2016-04-12/8378563200_hourlyCalories_merged.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4q/_mr1kbyx3hj3j1xbqv071trh0000gn/T/ipykernel_39419/3039414713.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['ActivityHour'] = pd.to_datetime(df['ActivityHour'])\n",
      "/var/folders/4q/_mr1kbyx3hj3j1xbqv071trh0000gn/T/ipykernel_39419/3039414713.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['ActivityHour'] = pd.to_datetime(df['ActivityHour'])\n",
      "/var/folders/4q/_mr1kbyx3hj3j1xbqv071trh0000gn/T/ipykernel_39419/3039414713.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['ActivityHour'] = pd.to_datetime(df['ActivityHour'])\n",
      "/var/folders/4q/_mr1kbyx3hj3j1xbqv071trh0000gn/T/ipykernel_39419/3039414713.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ./8378563200/2016-03-11/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-12/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-13/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-14/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-15/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-16/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-17/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-18/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-19/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-20/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-21/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-22/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-23/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-24/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-25/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-26/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-27/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-28/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-29/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-30/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-03-31/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-04-01/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-04-02/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-04-03/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-04-04/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-04-05/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-04-06/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-04-07/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-04-08/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-04-09/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-04-10/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-04-11/8378563200_minuteSleep_merged.csv\n",
      "Saved ./8378563200/2016-04-12/8378563200_minuteSleep_merged.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4q/_mr1kbyx3hj3j1xbqv071trh0000gn/T/ipykernel_39419/3039414713.py:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['ActivityMinute'] = pd.to_datetime(df['ActivityMinute'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ./8378563200/2016-03-12/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-13/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-14/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-15/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-16/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-17/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-18/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-19/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-20/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-21/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-22/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-23/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-24/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-25/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-26/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-27/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-28/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-29/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-30/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-31/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-01/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-02/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-03/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-04/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-05/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-06/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-07/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-08/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-09/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-10/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-11/8378563200_minuteCaloriesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-12/8378563200_minuteCaloriesNarrow_merged.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4q/_mr1kbyx3hj3j1xbqv071trh0000gn/T/ipykernel_39419/3039414713.py:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['ActivityMinute'] = pd.to_datetime(df['ActivityMinute'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ./8378563200/2016-03-12/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-13/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-14/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-15/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-16/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-17/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-18/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-19/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-20/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-21/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-22/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-23/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-24/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-25/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-26/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-27/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-28/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-29/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-30/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-03-31/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-01/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-02/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-03/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-04/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-05/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-06/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-07/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-08/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-09/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-10/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-11/8378563200_minuteIntensitiesNarrow_merged.csv\n",
      "Saved ./8378563200/2016-04-12/8378563200_minuteIntensitiesNarrow_merged.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4q/_mr1kbyx3hj3j1xbqv071trh0000gn/T/ipykernel_39419/3039414713.py:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['ActivityMinute'] = pd.to_datetime(df['ActivityMinute'])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Call the function with the base directory\u001b[39;00m\n\u001b[1;32m     55\u001b[0m base_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 56\u001b[0m \u001b[43msplit_and_save_by_day_within_id_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m, in \u001b[0;36msplit_and_save_by_day_within_id_directory\u001b[0;34m(base_directory)\u001b[0m\n\u001b[1;32m     18\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActivityDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActivityDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActivityMinute\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m---> 20\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActivityMinute\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mActivityMinute\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActivityHour\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     22\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActivityHour\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActivityHour\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/micromamba/envs/cs109a/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m~/micromamba/envs/cs109a/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m--> 435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     out_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/micromamba/envs/cs109a/lib/python3.12/site-packages/pandas/core/arrays/datetimes.py:2398\u001b[0m, in \u001b[0;36mobjects_to_datetime64\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[0m\n\u001b[1;32m   2395\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[0;32m-> 2398\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2403\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabbrev_to_npy_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_unit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2405\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2408\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m   2409\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[1;32m   2410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, tz_parsed\n",
      "File \u001b[0;32mtslib.pyx:414\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtslib.pyx:553\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mconversion.pyx:641\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsing.pyx:336\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsing.pyx:660\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/micromamba/envs/cs109a/lib/python3.12/site-packages/dateutil/parser/_parser.py:719\u001b[0m, in \u001b[0;36mparser._parse\u001b[0;34m(self, timestr, dayfirst, yearfirst, fuzzy, fuzzy_with_tokens)\u001b[0m\n\u001b[1;32m    716\u001b[0m     yearfirst \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39myearfirst\n\u001b[1;32m    718\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result()\n\u001b[0;32m--> 719\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[43m_timelex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# Splits the timestr into tokens\u001b[39;00m\n\u001b[1;32m    721\u001b[0m skipped_idxs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    723\u001b[0m \u001b[38;5;66;03m# year/month/day list\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/cs109a/lib/python3.12/site-packages/dateutil/parser/_parser.py:201\u001b[0m, in \u001b[0;36m_timelex.split\u001b[0;34m(cls, s)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mcls\u001b[39m, s):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/cs109a/lib/python3.12/site-packages/dateutil/parser/_parser.py:189\u001b[0m, in \u001b[0;36m_timelex.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    190\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to split dataframe by day and save to CSV within each ID folder\n",
    "def split_and_save_by_day_within_id_directory(base_directory):\n",
    "    for user_id in os.listdir(base_directory):\n",
    "        user_dir = os.path.join(base_directory, user_id)\n",
    "        if os.path.isdir(user_dir):\n",
    "            for filename in os.listdir(user_dir):\n",
    "                file_path = os.path.join(user_dir, filename)\n",
    "                if filename.endswith('.csv'):\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    \n",
    "                    # Ensure the date column is in datetime format\n",
    "                    if 'Date' in df.columns:\n",
    "                        df['Date'] = pd.to_datetime(df['Date'])\n",
    "                    elif 'ActivityDate' in df.columns:\n",
    "                        df['ActivityDate'] = pd.to_datetime(df['ActivityDate'])\n",
    "                    elif 'ActivityMinute' in df.columns:\n",
    "                        df['ActivityMinute'] = pd.to_datetime(df['ActivityMinute'])\n",
    "                    elif 'ActivityHour' in df.columns:\n",
    "                        df['ActivityHour'] = pd.to_datetime(df['ActivityHour'])\n",
    "                    elif 'Time' in df.columns:\n",
    "                        df['Time'] = pd.to_datetime(df['Time'])\n",
    "                    elif 'date' in df.columns:\n",
    "                        df['date'] = pd.to_datetime(df['date'])\n",
    "                    \n",
    "                    # Group by day\n",
    "                    if 'Date' in df.columns:\n",
    "                        grouped = df.groupby(df['Date'].dt.date)\n",
    "                    elif 'ActivityDate' in df.columns:\n",
    "                        grouped = df.groupby(df['ActivityDate'].dt.date)\n",
    "                    elif 'ActivityMinute' in df.columns:\n",
    "                        grouped = df.groupby(df['ActivityMinute'].dt.date)\n",
    "                    elif 'ActivityHour' in df.columns:\n",
    "                        grouped = df.groupby(df['ActivityHour'].dt.date)\n",
    "                    elif 'Time' in df.columns:\n",
    "                        grouped = df.groupby(df['Time'].dt.date)\n",
    "                    elif 'date' in df.columns:\n",
    "                        grouped = df.groupby(df['date'].dt.date)\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    # Save each group to a CSV file within the respective ID folder\n",
    "                    for day, group in grouped:\n",
    "                        day_str = day.strftime('%Y-%m-%d')\n",
    "                        date_dir = os.path.join(user_dir, day_str)\n",
    "                        os.makedirs(date_dir, exist_ok=True)\n",
    "                        \n",
    "                        output_filename = os.path.join(date_dir, f\"{filename}\")\n",
    "                        group.to_csv(output_filename, index=False)\n",
    "                        print(f\"Saved {output_filename}\")\n",
    "\n",
    "# Call the function with the base directory\n",
    "base_directory = '.'\n",
    "split_and_save_by_day_within_id_directory(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "\n",
    "def create_daily_steps_zip(data_dict, base_directory):\n",
    "    # Ensure the base directory exists\n",
    "    os.makedirs(base_directory, exist_ok=True)\n",
    "    \n",
    "    # Process each file in the data dictionary\n",
    "    for filename, df in data_dict.items():\n",
    "        if 'ActivityHour' in df.columns:\n",
    "            df['ActivityHour'] = pd.to_datetime(df['ActivityHour'])\n",
    "            df['Date'] = df['ActivityHour'].dt.date\n",
    "            grouped = df.groupby(['Id', 'Date'])['StepTotal'].sum().reset_index()\n",
    "            \n",
    "            for user_id, group in grouped.groupby('Id'):\n",
    "                user_dir = os.path.join(base_directory, str(user_id))\n",
    "                os.makedirs(user_dir, exist_ok=True)\n",
    "                \n",
    "                zip_filename = os.path.join(user_dir, f\"{user_id}_daily_steps.zip\")\n",
    "                with ZipFile(zip_filename, 'w') as zipf:\n",
    "                    for _, row in group.iterrows():\n",
    "                        day_str = row['Date'].strftime('%Y-%m-%d')\n",
    "                        steps = row['StepTotal']\n",
    "                        csv_filename = f\"{day_str}_{steps}_steps.csv\"\n",
    "                        csv_path = os.path.join(user_dir, csv_filename)\n",
    "                        \n",
    "                        # Save the daily data to a CSV file\n",
    "                        daily_df = df[(df['Id'] == user_id) & (df['Date'] == row['Date'])]\n",
    "                        daily_df.to_csv(csv_path, index=False)\n",
    "                        \n",
    "                        # Add the CSV file to the zip\n",
    "                        zipf.write(csv_path, arcname=csv_filename)\n",
    "                        os.remove(csv_path)  # Remove the CSV file after adding to zip\n",
    "                        \n",
    "                print(f\"Created zip file: {zip_filename}\")\n",
    "\n",
    "# Call the function\n",
    "base_directory = '.'\n",
    "create_daily_steps_zip(data_dict, base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_activity_improvement(directory_path):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from scipy import stats\n",
    "    \n",
    "    # Load all CSV files into a list of dataframes\n",
    "    csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "    \n",
    "    if len(csv_files) == 0:\n",
    "        return \"No CSV files found in the directory.\"\n",
    "\n",
    "    # Create a list to hold the data\n",
    "    all_data = []\n",
    "\n",
    "    # Load each CSV into a DataFrame and append to the list\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        daily_data = pd.read_csv(file_path)\n",
    "        all_data.append(daily_data)\n",
    "\n",
    "    # Concatenate all daily data into one DataFrame\n",
    "    df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Assuming the CSVs have 'date', 'steps', and 'calories' columns\n",
    "    # Convert 'date' to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Sort data by date\n",
    "    df = df.sort_values(by='date')\n",
    "\n",
    "    # Get the most recent day\n",
    "    most_recent_day_data = df.tail(1)[['steps', 'calories']].mean()\n",
    "\n",
    "    # Check if there is enough data for at least one week (7 days)\n",
    "    if len(df) >= 7:\n",
    "        # Get the most recent week data\n",
    "        recent_week_data = df.tail(7)[['steps', 'calories']].mean()\n",
    "    else:\n",
    "        # If there isn't enough data for a full week, use whatever data is available\n",
    "        recent_week_data = df[['steps', 'calories']].mean()\n",
    "\n",
    "    # Perform t-tests to compare the most recent day with the previous period (week or partial week)\n",
    "    steps_t_stat, steps_p_val = stats.ttest_rel(df['steps'].tail(min(len(df), 7)), df['steps'].tail(1).repeat(min(len(df), 7)))\n",
    "    calories_t_stat, calories_p_val = stats.ttest_rel(df['calories'].tail(min(len(df), 7)), df['calories'].tail(1).repeat(min(len(df), 7)))\n",
    "\n",
    "    # Determine if there is significant improvement (p-value < 0.05 and most recent day steps/calories are greater)\n",
    "    steps_improved = steps_p_val < 0.05 and most_recent_day_data['steps'] > recent_week_data['steps']\n",
    "    calories_improved = calories_p_val < 0.05 and most_recent_day_data['calories'] > recent_week_data['calories']\n",
    "\n",
    "    # Return the results\n",
    "    return {\n",
    "        \"Steps Improved\": steps_improved,\n",
    "        \"Calories Improved\": calories_improved,\n",
    "        \"Steps p-value\": steps_p_val,\n",
    "        \"Calories p-value\": calories_p_val\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "# result = analyze_activity_improvement('path_to_your_data_folder')\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  steps  calories\n",
      "27 2016-04-03  10016      1851\n",
      "24 2016-04-04  14538      2037\n",
      "23 2016-04-05  14844      2081\n",
      "4  2016-04-06  11974      1859\n",
      "10 2016-04-07  10198      1753\n",
      "0  2016-04-08  12521      1893\n",
      "13 2016-04-09  12432      1884\n",
      "15 2016-04-10  10057      1757\n",
      "{'Steps Improved': np.False_, 'Predicted Steps': np.float64(12155.857142857143), 'Actual Steps': np.int64(10057), 'Calories Improved': np.False_, 'Predicted Calories': np.float64(1834.4285714285713), 'Actual Calories': np.int64(1757)}\n"
     ]
    }
   ],
   "source": [
    "def analyze_activity_improvement_with_regression(patient_id_directory):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    import numpy as np\n",
    "\n",
    "    # Initialize lists to hold the data\n",
    "    all_steps = []\n",
    "    all_calories = []\n",
    "    all_dates = []\n",
    "\n",
    "    # Loop through each date folder within the patient ID directory\n",
    "    for date_folder in os.listdir(patient_id_directory):\n",
    "        date_folder_path = os.path.join(patient_id_directory, date_folder)\n",
    "        if os.path.isdir(date_folder_path):\n",
    "            for file in os.listdir(date_folder_path):\n",
    "                if file.endswith('.csv'):\n",
    "                    file_path = os.path.join(date_folder_path, file)\n",
    "                    daily_data = pd.read_csv(file_path)\n",
    "                    if 'StepTotal' in daily_data.columns:\n",
    "                        total_steps = daily_data['StepTotal'].sum()\n",
    "                        all_steps.append(total_steps)\n",
    "                        all_dates.append(pd.to_datetime(date_folder))\n",
    "                    if 'Calories' in daily_data.columns and 'ActivityHour' in daily_data.columns:\n",
    "                        total_calories = daily_data['Calories'].sum()\n",
    "                        all_calories.append(total_calories)\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame({\n",
    "        'date': all_dates,\n",
    "        'steps': all_steps,\n",
    "        'calories': all_calories\n",
    "    })\n",
    "\n",
    "    # Sort data by date descending\n",
    "    df = df.sort_values(by='date')\n",
    "\n",
    "    # Take the most recent 8 days (1 day for comparison, 7 days for the previous period)\n",
    "    df = df.tail(8)\n",
    "    print(df)\n",
    "    # Separate the most recent day and the previous 7 days\n",
    "    recent_week_df = df.head(7)\n",
    "    most_recent_day_df = df.tail(1)\n",
    "\n",
    "    # Fit a linear regression model for steps\n",
    "    X_week = np.arange(len(recent_week_df)).reshape(-1, 1)  # Day indices for the previous week\n",
    "    y_steps_week = recent_week_df['steps'].values\n",
    "    y_calories_week = recent_week_df['calories'].values\n",
    "\n",
    "    # Linear regression for steps\n",
    "    model_steps = LinearRegression()\n",
    "    model_steps.fit(X_week, y_steps_week)\n",
    "    \n",
    "    # Linear regression for calories\n",
    "    model_calories = LinearRegression()\n",
    "    model_calories.fit(X_week, y_calories_week)\n",
    "\n",
    "    # Predict the steps and calories for the next day (i.e., day 7)\n",
    "    next_day_index = np.array([[7]])  # The next day to predict for (8th day)\n",
    "    predicted_steps = model_steps.predict(next_day_index)\n",
    "    predicted_calories = model_calories.predict(next_day_index)\n",
    "\n",
    "    # Get the actual steps and calories for the most recent day\n",
    "    actual_steps = most_recent_day_df['steps'].values[0]\n",
    "    actual_calories = most_recent_day_df['calories'].values[0]\n",
    "\n",
    "    # Compare the predicted vs actual\n",
    "    steps_improved = actual_steps > predicted_steps[0]\n",
    "    calories_improved = actual_calories > predicted_calories[0]\n",
    "\n",
    "    # Return the results\n",
    "    return {\n",
    "        \"Steps Improved\": steps_improved,\n",
    "        \"Predicted Steps\": predicted_steps[0],\n",
    "        \"Actual Steps\": actual_steps,\n",
    "        \"Calories Improved\": calories_improved,\n",
    "        \"Predicted Calories\": predicted_calories[0],\n",
    "        \"Actual Calories\": actual_calories\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "result = analyze_activity_improvement_with_regression('1503960366')\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
